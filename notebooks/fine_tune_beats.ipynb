{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import random\n",
    "\n",
    "from BEATs.Tokenizers import TokenizersConfig, Tokenizers\n",
    "from BEATs.BEATs import BEATs, BEATsConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/data/ESC-50-master\"\n",
    "audio = glob.glob(data_folder + \"/audio/*.wav\", recursive=True)\n",
    "labels = pd.read_csv(os.path.join(data_folder, \"meta/esc50.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'merge'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df_audio \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(audio, columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mfilepath\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m df_audio[\u001b[39m\"\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m [f\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m audio]\n\u001b[0;32m----> 3\u001b[0m filepath_labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39;49mmerge(df_audio, how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minner\u001b[39m\u001b[39m\"\u001b[39m, on\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/generic.py:5907\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5900\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5901\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5902\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5903\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5904\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5905\u001b[0m ):\n\u001b[1;32m   5906\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5907\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'merge'"
     ]
    }
   ],
   "source": [
    "df_audio = pd.DataFrame(audio, columns=[\"filepath\"])\n",
    "df_audio[\"filename\"] = [f.split(\"/\")[-1] for f in audio]\n",
    "filepath_labels = labels.merge(df_audio, how=\"inner\", on=\"filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BEATs(\n",
       "  (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "  (patch_embedding): Conv2d(1, 512, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "  (dropout_input): Dropout(p=0.1, inplace=False)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (pos_conv): Sequential(\n",
       "      (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "      (1): SamePad()\n",
       "      (2): GELU()\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('/data/BEATs/BEATs_iter3_plus_AS2M.pt')\n",
    "\n",
    "cfg = BEATsConfig({\n",
    "    **checkpoint['cfg'],\n",
    "    \"predictor_class\": 50,\n",
    "    \"finetuned_model\": False\n",
    "})\n",
    "        \n",
    "#cfg = BEATsConfig(checkpoint['cfg'])\n",
    "BEATs_model = BEATs(cfg)\n",
    "BEATs_model.load_state_dict(checkpoint['model'])\n",
    "BEATs_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
